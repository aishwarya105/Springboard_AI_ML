{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read the video frame by frame and store a few frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_capture(filename):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    count = 0\n",
    "    frame_prefix = filename.split('/')[6]+\"_\"\\\n",
    "                  +filename.split('/')[7]+\"_\"\\\n",
    "                  +filename.split('/')[8]+\"_\"\\\n",
    "                  +(filename.split('/')[9]).split('.')[0]\n",
    "    \n",
    "    frameRate = cap.get(5)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            # Display the resulting frame : cv2.imshow('Frame',frame)\n",
    "            \n",
    "            if (frameId % math.floor(frameRate) == 0):\n",
    "                framename = '/media/mynewdrive/data/Retail_AI/3DPeS/'+frame_prefix+\"_frame%d.jpg\" % count\n",
    "                if not cv2.imwrite(framename, frame):\n",
    "                    raise Exception(\"Could not write image\")\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            count+=1\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "my_dir = '/media/mynewdrive/data/Retail_AI/3DPeS/Video_Set_1/'\n",
    "for dir_2 in os.listdir(my_dir):\n",
    "    dir_3 = os.path.join(my_dir,dir_2)\n",
    "    for dir_4 in os.listdir(dir_3):\n",
    "        dir_5 = os.path.join(dir_3,dir_4)\n",
    "        for dir_6 in os.listdir(dir_5):\n",
    "            filename = os.path.join(dir_5,dir_6)\n",
    "            frame_capture(filename)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YoloV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load yol\n",
    "net = cv2.dnn.readNet(\"yolov3.weights.1\",\"darknet/cfg/yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "                   \n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to detect object in one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_frame (img_name):\n",
    "    img = cv2.imread(img_name)\n",
    "    img = cv2.resize(img, None, fx=0.34, fy=0.4)\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    #detect objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416,416),(0,0,0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                #Object detected\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*width)\n",
    "                cv2.circle(img,(center_x,center_y),10,(0,255,0),2)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * width)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.6)\n",
    "\n",
    "    yolo_img_name = img_name.split('/')[0]+\"_YOLO/\"+(img_name.split('/')[1]).split('.')[0]+\"_yolo.jpg\"\n",
    "    cv2.imwrite(yolo_img_name,img)\n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_name = 'Video_Set_1_Frames'\n",
    "count = 0\n",
    "for frames in os.listdir(dir_name):\n",
    "    count += 1\n",
    "    print(count)\n",
    "    read_detect_show(dir_name+\"/\"+frames)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to detect and bound objects in a video and store output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(file_name,label = 'person'):\n",
    "    print(\"Current file :\",file_name)\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "    frame_count = 0\n",
    "    img_array = []\n",
    "    metadata_file = file_name.split('.')[0]+'.txt'\n",
    "    video_output = file_name.split('.')[0]+'_yolo.avi'\n",
    "    label_index = classes.index(label)\n",
    "    outF = open(metadata_file, \"w\")\n",
    "    while True:\n",
    "        _,frame = cap.read()\n",
    "        frame_count+=1\n",
    "        if(_ != True):\n",
    "            break\n",
    "            \n",
    "        height, width, channels = frame.shape\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416,416), (0,0,0), True, crop = False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "        \n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        \n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5 and class_id == label_index:\n",
    "                    #Object detected\n",
    "                    center_x = int(detection[0]*width)\n",
    "                    center_y = int(detection[1]*height)\n",
    "                    \n",
    "                    #draw circle\n",
    "                    cv2.circle(frame,(center_x,center_y), radius = 5, color = (0,255,0), thickness = 1)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * width)\n",
    "                    \n",
    "                     # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "        \n",
    "        \n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.6)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN          \n",
    "    \n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(frame, label, (x, y + 30), font, 1, color, 2)\n",
    "\n",
    "                #create a text file to output bounding boxes\n",
    "                # write frame number and coordinates\n",
    "                outF.write(\"Frame# %f : %f %f %f %f\\n\" % (frame_count,x,y,w,h))\n",
    "\n",
    "                    \n",
    "        img_array.append(frame)\n",
    "        #cv2.imshow(\"Image\",frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    outF.close()   \n",
    "\n",
    "\n",
    "    #Create the output video file\n",
    "    size = (width,height)\n",
    "    out = cv2.VideoWriter(video_output,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get all the video files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    # create a list of files and sub directories\n",
    "    #names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    listOfFile.sort()\n",
    "    #iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        #create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        #If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "file_list = getListOfFiles('Video_Set_1/')\n",
    "first_start_time = time.time()\n",
    "for video_file in file_list:\n",
    "    file_start_time = time.time()\n",
    "    detect_video(video_file)\n",
    "    print(\"--- %s seconds ---\" %(time.time() - start_time))\n",
    "print(\"--- %s seconds ---\" %(time.time() - first_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to parallelize code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to list the previous path if the list is not a dir \n",
    "def getlastdir(dirName):\n",
    "    alllastdir = list()\n",
    "    listOfFile = os.listdir(dirName) #gets the name of the subdirectory\n",
    "    for entry in listOfFile:\n",
    "        fullPath = os.path.join(dirName, entry) #prints Video_Set_1/ID_X\n",
    "        if os.path.isdir(fullPath):\n",
    "            alllastdir = alllastdir + getlastdir(fullPath)\n",
    "        else:\n",
    "            alllastdir.append(dirName)\n",
    "    return alllastdir\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Video_Set_Parallel/ID_13/Camera_1', 'Video_Set_Parallel/ID_13/Camera_2', 'Video_Set_Parallel/ID_13/Camera_4', 'Video_Set_Parallel/ID_14/Camera_1', 'Video_Set_Parallel/ID_14/Camera_2', 'Video_Set_Parallel/ID_14/Camera_4', 'Video_Set_Parallel/ID_16/Camera_1', 'Video_Set_Parallel/ID_16/Camera_2', 'Video_Set_Parallel/ID_16/Camera_4', 'Video_Set_Parallel/ID_04/Camera_1', 'Video_Set_Parallel/ID_04/Camera_2', 'Video_Set_Parallel/ID_04/Camera_3', 'Video_Set_Parallel/ID_12/Camera_1', 'Video_Set_Parallel/ID_12/Camera_3', 'Video_Set_Parallel/ID_09/Camera_1', 'Video_Set_Parallel/ID_09/Camera_2', 'Video_Set_Parallel/ID_09/Camera_3', 'Video_Set_Parallel/ID_11/Camera_1', 'Video_Set_Parallel/ID_11/Camera_2', 'Video_Set_Parallel/ID_11/Camera_3', 'Video_Set_Parallel/ID_01/Camera_1', 'Video_Set_Parallel/ID_01/Camera_2', 'Video_Set_Parallel/ID_01/Camera_3', 'Video_Set_Parallel/ID_08/Camera_1', 'Video_Set_Parallel/ID_08/Camera_2', 'Video_Set_Parallel/ID_08/Camera_3', 'Video_Set_Parallel/ID_07/Camera_1', 'Video_Set_Parallel/ID_07/Camera_2', 'Video_Set_Parallel/ID_07/Camera_3', 'Video_Set_Parallel/ID_19/Camera_1', 'Video_Set_Parallel/ID_19/Camera_2', 'Video_Set_Parallel/ID_15/Camera_1', 'Video_Set_Parallel/ID_15/Camera_2', 'Video_Set_Parallel/ID_15/Camera_4', 'Video_Set_Parallel/ID_18/Camera_1', 'Video_Set_Parallel/ID_18/Camera_4', 'Video_Set_Parallel/ID_03/Camera_1', 'Video_Set_Parallel/ID_03/Camera_2', 'Video_Set_Parallel/ID_03/Camera_3', 'Video_Set_Parallel/ID_17/Camera_1', 'Video_Set_Parallel/ID_17/Camera_4', 'Video_Set_Parallel/ID_05/Camera_1', 'Video_Set_Parallel/ID_05/Camera_2', 'Video_Set_Parallel/ID_05/Camera_3', 'Video_Set_Parallel/ID_06/Camera_1', 'Video_Set_Parallel/ID_06/Camera_2', 'Video_Set_Parallel/ID_06/Camera_3', 'Video_Set_Parallel/ID_20/Camera_1', 'Video_Set_Parallel/ID_20/Camera_2', 'Video_Set_Parallel/ID_20/Camera_3', 'Video_Set_Parallel/ID_10/Camera_1', 'Video_Set_Parallel/ID_10/Camera_2', 'Video_Set_Parallel/ID_10/Camera_3', 'Video_Set_Parallel/ID_02/Camera_1', 'Video_Set_Parallel/ID_02/Camera_2', 'Video_Set_Parallel/ID_02/Camera_3']\n"
     ]
    }
   ],
   "source": [
    "dirName = 'Video_Set_Parallel/'\n",
    "dirlist = getlastdir(dirName)\n",
    "dirlist = list(dict.fromkeys(dirlist))\n",
    "print(dirlist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video_parallel(dirname,label = 'person'):\n",
    "    for video in os.listdir(dirname):\n",
    "        file_name = os.path.join(dirname,video)\n",
    "        print(\"Current file :\",file_name)\n",
    "        cap = cv2.VideoCapture(file_name)\n",
    "        frame_count = 0\n",
    "        img_array = []\n",
    "        metadata_file = file_name.split('.')[0]+'.txt'\n",
    "        video_output = file_name.split('.')[0]+'_yolo.avi'\n",
    "        label_index = classes.index(label)\n",
    "        outF = open(metadata_file, \"w\")\n",
    "        while True:\n",
    "            _,frame = cap.read()\n",
    "            frame_count+=1\n",
    "            if(_ != True):\n",
    "                break\n",
    "\n",
    "            height, width, channels = frame.shape\n",
    "            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416,416), (0,0,0), True, crop = False)\n",
    "            net.setInput(blob)\n",
    "            outs = net.forward(output_layers)\n",
    "\n",
    "            class_ids = []\n",
    "            confidences = []\n",
    "            boxes = []\n",
    "\n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    confidence = scores[class_id]\n",
    "                    if confidence > 0.5 and class_id == label_index:\n",
    "                        #Object detected\n",
    "                        center_x = int(detection[0]*width)\n",
    "                        center_y = int(detection[1]*height)\n",
    "\n",
    "                        #draw circle\n",
    "                        cv2.circle(frame,(center_x,center_y), radius = 5, color = (0,255,0), thickness = 1)\n",
    "                        w = int(detection[2] * width)\n",
    "                        h = int(detection[3] * width)\n",
    "\n",
    "                         # Rectangle coordinates\n",
    "                        x = int(center_x - w / 2)\n",
    "                        y = int(center_y - h / 2)\n",
    "\n",
    "                        boxes.append([x, y, w, h])\n",
    "                        confidences.append(float(confidence))\n",
    "                        class_ids.append(class_id)\n",
    "\n",
    "\n",
    "            indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.6)\n",
    "            font = cv2.FONT_HERSHEY_PLAIN          \n",
    "\n",
    "            for i in range(len(boxes)):\n",
    "                if i in indexes:\n",
    "                    x, y, w, h = boxes[i]\n",
    "                    label = str(classes[class_ids[i]])\n",
    "                    color = colors[i]\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                    cv2.putText(frame, label, (x, y + 30), font, 1, color, 2)\n",
    "\n",
    "                    #create a text file to output bounding boxes\n",
    "                    # write frame number and coordinates\n",
    "                    t = time.localtime()\n",
    "                    timestamp = time.strftime('%b-%d-%Y_%H%M', t)\n",
    "                    outF.write(\"Frame#:%s, Dimensions:%f %f %f %f, Timestamp: %s\\n\" % (frame_count,x,y,w,h,timestamp))\n",
    "\n",
    "\n",
    "            img_array.append(frame)\n",
    "            #cv2.imshow(\"Image\",frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        outF.close()   \n",
    "\n",
    "\n",
    "        #Create the output video file\n",
    "        size = (width,height)\n",
    "        out = cv2.VideoWriter(video_output,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "        for i in range(len(img_array)):\n",
    "            out.write(img_array[i])\n",
    "        out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file : Video_Set_Parallel/ID_13/Camera_4/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_13/Camera_1/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_09/Camera_1/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_09/Camera_3/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_16/Camera_4/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_14/Camera_2/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_04/Camera_2/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_12/Camera_1/Seq_1.avi\n",
      "Current file : Video_Set_Parallel/ID_16/Camera_1/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_01/Camera_1/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_11/Camera_2/Seq_2.avi\n",
      "Current file : Video_Set_Parallel/ID_01/Camera_3/Seq_2.avi\n"
     ]
    }
   ],
   "source": [
    "# Parallelizing using Pool.apply()\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "first_start_time = time.time()\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "pool.map(detect_video_parallel, [(dir_name+\"/\") for dir_name in dirlist])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()  \n",
    "\n",
    "print(\"--- %s seconds ---\" %(time.time() - first_start_time))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
