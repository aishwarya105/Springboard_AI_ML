{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read the video frame by frame and store a few frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_capture(filename):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    count = 0\n",
    "    frame_prefix = filename.split('/')[6]+\"_\"\\\n",
    "                  +filename.split('/')[7]+\"_\"\\\n",
    "                  +filename.split('/')[8]+\"_\"\\\n",
    "                  +(filename.split('/')[9]).split('.')[0]\n",
    "    \n",
    "    frameRate = cap.get(5)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            # Display the resulting frame : cv2.imshow('Frame',frame)\n",
    "            \n",
    "            if (frameId % math.floor(frameRate) == 0):\n",
    "                framename = '/media/mynewdrive/data/Retail_AI/3DPeS/'+frame_prefix+\"_frame%d.jpg\" % count\n",
    "                if not cv2.imwrite(framename, frame):\n",
    "                    raise Exception(\"Could not write image\")\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            count+=1\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "my_dir = '/media/mynewdrive/data/Retail_AI/3DPeS/Video_Set_1/'\n",
    "for dir_2 in os.listdir(my_dir):\n",
    "    dir_3 = os.path.join(my_dir,dir_2)\n",
    "    for dir_4 in os.listdir(dir_3):\n",
    "        dir_5 = os.path.join(dir_3,dir_4)\n",
    "        for dir_6 in os.listdir(dir_5):\n",
    "            filename = os.path.join(dir_5,dir_6)\n",
    "            frame_capture(filename)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YoloV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load yolo\n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights.1\",\"darknet/cfg/yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Lets try counting all file names\n",
    "# dir_name = 'Video_Set_1_Frames'\n",
    "# count = 0\n",
    "# for frames in os.listdir(dir_name):\n",
    "#     count += 1\n",
    "# count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_detect_show (img_name):\n",
    "    img = cv2.imread(img_name)\n",
    "    img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    #detect objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416,416),(0,0,0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                #Object detected\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*width)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * width)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(img, label, (x, y + 30), font, 1, color, 3)\n",
    "    yolo_img_name = img_name.split('/')[0]+\"_YOLO/\"+(img_name.split('/')[1]).split('.')[0]+\"_yolo.jpg\"\n",
    "    cv2.imwrite(yolo_img_name,img)\n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_name = 'Video_Set_1_Frames'\n",
    "count = 0\n",
    "for frames in os.listdir(dir_name):\n",
    "    count += 1\n",
    "    print(count)\n",
    "    read_detect_show(dir_name+\"/\"+frames)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
